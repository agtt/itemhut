#!/usr/bin/python2

from bs4 import BeautifulSoup
import requests
import re

import os.path
import sys

sys.path.append("/omark/pydb/")
import dbconn

flat_file_page = requests.get("http://www.amazon.com/gp/help/customer/display.html?nodeId=200186090")

file_soup = BeautifulSoup(flat_file_page.text)

def camel_to_underscore(name):
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

def create_schemas(sfile):
    for link in sfile.find_all("a"):
        candidate_link = link.get("href")
        if (candidate_link is not None
            and "Flat.File" in candidate_link):
            junk, sep, name = candidate_link.partition("Flat.File.")
            final_name, dot, xl = name.partition(".")
            schema_name = "amazon_" + camel_to_underscore(final_name)
            if schema_name not in ["amazon_inventory_loader",
                                   "amazon_price_inventory"]:
                dbconn.cur.execute("""create schema {0};""".format(schema_name))


def save_excel_files(sfile):
    print("starting")
    for link in sfile.find_all("a"):
        candidate_link = link.get("href")
        if (candidate_link is not None
            and "Flat.File" in candidate_link):
            xfile = requests.get(candidate_link)
            if xfile:
                ofolder = open("xtest", "wb")
                ofolder.write(xfile.read())
                ofolder.close()
    print("done")
            
create_schemas(file_soup)
save_excel_files(file_soup)

dbconn.conn.commit()
dbconn.cur.close()

print("success")
